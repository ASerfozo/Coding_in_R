---
title: "Airbnb Rome Price Prediction"
author: "Attila Serfozo"
date: '2021.02.02 '
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}

rm(list=ls())
# Set environment
library(tidyverse)
library(caret)
library(skimr) # for skimr data view
library(Hmisc) # for describe variable
library(ggplot2)
library(ggthemes)
library(grid) # for plot grid
library(glmnet)
library(stargazer)
library(xtable)
library(directlabels)
library(knitr)
library(cowplot) # for plot grid and boxplot
library(rattle)
library(ranger)

# Set directory
dir<-"D:/Egyetem/CEU/Winter_Term/Data_Analysis_3/DA3_R/Assignment 1"

data_in  <- paste0(dir,"/data/clean/")
data_out <- paste0(dir,"/out/")

options(digits = 3)
source("D:/Egyetem/CEU/Winter_Term/Data_Analysis_3/DA3_R/Assignment 1/codes/theme_bg.R")
source("D:/Egyetem/CEU/Winter_Term/Data_Analysis_3/DA3_R/Assignment 1/codes/da_helper_functions.R")

# Import data
data <-
  read_csv(paste0(data_in,"airbnb_rome_cleaned.csv")) %>%
  mutate_if(is.character, factor)

to_drop <- c("usd_cleaning_fee", "p_host_response_rate", "d_reviews_per_month")
data <- data %>%
  select(-one_of(to_drop))

```

## Abstract

In this project my goal is to build a price prediction model for apartments able to host 2-6 persons in Rome based on local Airbnb data. During the exercise I cleaned the downloaded data, grouped variables and created six different models to predict prices. Based on the results the extended Random Forest model provided the best prediction with 44.9 USD RMSE and 40% R-squared values. The key predictor variables were number of accommodates, number of bathrooms, days since first review, review scores rating, room type, number of beds, air conditioning and free street paring availability, number of reviews and cancellation policy. These 10 predictors altogether account for approximately 48% of the model prediction power. From the subsample performance it is important to highlight that the model predicted prices of the III, IV and VI neighbourhood of Rome pretty badly, which probably caused some part of the RMSE effect of the model. Overall the model predicted the prices relatively good, but we can state that it tends to overprice the Airbnbs of Rome.

## Introduction

The aim of this project is to build a price prediction model for apartments in Rome based on available Airbnb data downloaded from Inside Airbnb (http://insideairbnb.com/get-the-data.html). The dataset represents the available Airbnbs to rent on 2019.10.15. In the exercise to provide an accurate prediction I will select our key predictors from all variables of the dataset including both the basic property attributes, reviews and amenities of properties. During the project I will estimate 6 different type of models including two OLS, a LASSO, a CART and  two Random Forest models and in the end I would like to finish with a final model with relatively good prediction power regarding it's RMSE and R-squared.

## Data Preparation

In the begining of the data preparation I started with 30 814 observations and 106 variables describing all available Airbnb accommodations in Rome on 2019.10.15. The scope of the project aims to predict prices of apartments and condominiums able to host 2 to 6 people. After filtering the data to these criteria 21 366 observations remained in the analysis. The main variable of interest is price in the analysis as the goal of the project is price prediction. Thus observations with missing prices needed to be excluded, in addition I excluded observations with prices above 500 euros marked as extreme values. In the end I finished with 21 299 observations. The distribution of prices can be found below on the histograms.

```{r  message=FALSE, warning=FALSE, echo=FALSE, out.width = '50%', fig.height=4}

ggplot(data=data, aes(x=price)) +
  geom_histogram(aes(y = (..count..)/sum(..count..)), binwidth = 10, boundary=0,
                 color = "black", fill = "indianred3") +
  coord_cartesian(xlim = c(0, 500)) +
  labs(title="Distribution of Rome Airbnb prices", x = "Price (US dollars)",y = "Percent")+
  scale_y_continuous(expand = c(0.00,0.00),limits=c(0, 0.15), breaks = seq(0, 0.15, by = 0.03), labels = scales::percent_format(1)) +
  scale_x_continuous(expand = c(0.00,0.00),limits=c(0,500), breaks = seq(0,500, 50)) +
  theme_bw() 


# lnprice -> closer to a normal distribution
ggplot(data=data, aes(x=ln_price)) +
  geom_histogram(aes(y = (..count..)/sum(..count..)), binwidth = 0.15,
                 color = "black", fill = "indianred3") +
  coord_cartesian(xlim = c(2.5, 6.5)) +
  scale_y_continuous(expand = c(0.00,0.00),limits=c(0, 0.15), breaks = seq(0, 0.15, by = 0.05), labels = scales::percent_format(5L)) +
  scale_x_continuous(expand = c(0.00,0.01),breaks = seq(2.4,6.6, 0.6)) +
  labs(title="Distribution of Rome log Airbnb prices",x = "ln(price, US dollars)",y = "Percent")+
  theme_bw() 

```

The larger task of the project was feature engineering. First, I needed to decide which variables to include in the analysis. Thus I separated my variables to 3 groups:

- **Basic variables** which consisted of the main variables of the prediction, including numerical variables such as number of accommodates (2-6), number of beds, days since first review and qualitative variables formatted to factors like property type (apartment or condominium), room type (Entire apartment, private or shared), bathrooms (1, 2 or 3), cancellation policy (flexible, moderate or strict), bed type (couch or real bed) and neighbourhood with the districts of Rome I to XV. 

- **Review variables** which consisted of the main variables of guest reviews, including number of reviews, review scores between 0-100, and review score flags, which indicates missing reviews.

- **Variables of amenities** was the hardest group to create as on Airbnb the property attributions are not consistent, because they can be added manually by typing them in. Due to the fact that they are added by hand there are several amenities pointing at the same attribute but using different words, thus I finished with 198 different amenities in my dataset. To merge similar attributes to one I used a for loop to match similar variables, the loop can be inspected in the preparation code R file. As a results I kept or merged important attributes to one  like air conditioning, washer, oven, pool, balcony, tub, free parking, elevator etc. In addition I dropped variables that based on my opinion would have insignificant effect on model results due to lacking enough number of true observations (less than 3% of the observations had it) or based on individual decision. In the end I finished with 50 amenities.

After creating the 3 groups the last task was handling missing values. There were 15 variables with missing values. From these 15, missing observations in bathrooms were replaced with 1 assuming there is at least 1 bathroom in an apartment, missing number of beds were replaced with the number of accommodates, missing minimum nights assumed 1 night stays and missing number of reviews were assumed as 1. Missing review scores rating were replaced with zeros indicating no reviews at the accommodation, an additional column was created with flags indicating that there is a missing value in that row. In the end USD cleaning fee and host response rate variables were dropped as there were too many missing values in them.

## Exploratory Data Analysis

After the data cleaning as a next step lI had a look at the main variables of the models. The boxplots of variables can be found below. Overall we can see that the larger apartment the more it costs. On the first two boxplots we can see that apartments able to host more persons or have more bathrooms are more expensive which connects to their size. Also based on data apartments are valued higher than condominiums. The next two charts below, shows that entire apartments costs an extra compared to private rooms or shared rooms and real beds worth more for guests then pull-out couches. The last two boxplots shows surprisingly that strict cancellations are more expensive than flexible ones, for me it was interesting as I prefer flexibility. Also we can see that in Rome the district I, II and XIII districts are the most expensive in average compared to the IV, VI and VII which are the cheapest across Rome. 

```{r  message=FALSE, warning=FALSE, echo=FALSE, out.width = '50%', fig.height=4}

# Distribution of price by number of accommodates with boxplot
# Larger places with more people are more expensive and Apartments are more expensive than condominiums
price_proptype_boxplot <- ggplot(data, aes(x = factor(n_accommodates), y = price,
                 fill = factor(f_property_type), color=factor(f_property_type))) +
  geom_boxplot(alpha=0.8, na.rm=T, outlier.shape = NA, width = 0.8) +
  stat_boxplot(geom = "errorbar", width = 0.8, size = 0.3, na.rm=T)+
  scale_color_manual(name="",
                     values=c("indianred","indianred4")) +
  scale_fill_manual(name="",
                    values=c("indianred","indianred4")) +
  labs(title="Distribution of price by number of accommodates", x = "Accomodates (Persons)",y = "Price (US dollars)")+
  scale_y_continuous(expand = c(0.01,0.01), limits=c(0, 400), breaks = seq(0,400, 50))+
  theme_bw() +
  theme(legend.position = c(0.3,0.8)        )
price_proptype_boxplot

# Distribution of price by number of bathrooms with boxplot
#  More bathroom means higher price
price_bathroom_boxplot <- ggplot(data = data, aes(x = f_bathroom, y = price)) +
  stat_boxplot(aes(group = f_bathroom), geom = "errorbar", width = 0.3,
               color = "black", size = 0.5, na.rm=T)+
  geom_boxplot(aes(group = f_bathroom),
               color = "black", fill = c("indianred2","indianred","indianred4"),
               size = 0.5, width = 0.6, na.rm=T, outlier.shape = NA) +
  scale_y_continuous(expand = c(0.01,0.01),limits = c(0,300), breaks = seq(0,300,100)) +
  labs(title="Distribution of price by number of bathrooms",x = "Nr of bathrooms",y = "Price (US dollars)")+
  theme_bw()
price_bathroom_boxplot

# Distribution of price by room type with boxplot
#   Entire apartments are much more expensive than private or shared rooms
price_roomtype_boxplot <- ggplot(data = data, aes(x = f_room_type, y = price)) +
  stat_boxplot(aes(group = f_room_type), geom = "errorbar", width = 0.3,
               color = "black", size = 0.5, na.rm=T)+
  geom_boxplot(aes(group = f_room_type),
               color = "black", fill = c("indianred2","indianred","indianred4"),
               size = 0.5, width = 0.6, na.rm=T, outlier.shape = NA) +
  scale_y_continuous(expand = c(0.01,0.01),limits = c(0,300), breaks = seq(0,300,100)) +
  labs(title="Distribution of price by room type",x = "Room type",y = "Price (US dollars)")+
  theme_bw()
price_roomtype_boxplot

# Distribution of price by bed type with boxplot
#   Real bed are more expensive
price_bed_boxplot <- ggplot(data = data, aes(x = f_bed_type, y = price)) +
  stat_boxplot(aes(group = f_bed_type), geom = "errorbar", width = 0.3,
               color = "black", size = 0.5, na.rm=T)+
  geom_boxplot(aes(group = f_bed_type),
               color = "black", fill = c("indianred2","indianred3"),
               size = 0.5, width = 0.6, na.rm=T, outlier.shape = NA) +
  scale_y_continuous(expand = c(0.01,0.01),limits = c(0,300), breaks = seq(0,300,100)) +
  labs(title="Distribution of price by bed type", x = "Bed type",y = "Price (US dollars)")+
  theme_bw()
price_bed_boxplot

# Distribution of price by cancellation type with boxplot
#   Strict cancellations are more expensive
price_cancellation_boxplot <- ggplot(data = data, aes(x = f_cancellation_policy, y = price)) +
  stat_boxplot(aes(group = f_cancellation_policy), geom = "errorbar", width = 0.3,
               color = "black", size = 0.5, na.rm=T)+
  geom_boxplot(aes(group = f_cancellation_policy),
               color = "black", fill = c("indianred2","indianred","indianred4"),
               size = 0.5, width = 0.6, na.rm=T, outlier.shape = NA) +
  scale_y_continuous(expand = c(0.01,0.01),limits = c(0,300), breaks = seq(0,300,100)) +
  labs(title="Distribution of price by cancellation type", x = "Cancellation type",y = "Price (US dollars)")+
  theme_bw()
price_cancellation_boxplot

# Distribution of price by neighbourhood with boxplot
#  The I. district is much more expensive
price_neighbourhood_boxplot <- ggplot(data = data, aes(x = f_neighbourhood_cleansed, y = price)) +
  stat_boxplot(aes(group = f_neighbourhood_cleansed), geom = "errorbar", width = 0.3,
               color = "black", size = 0.5, na.rm=T)+
  geom_boxplot(aes(group = f_neighbourhood_cleansed),
               color = "black", fill = "indianred3",
               size = 0.5, width = 0.6, na.rm=T, outlier.shape = NA) +
  scale_y_continuous(expand = c(0.01,0.01),limits = c(0,300), breaks = seq(0,300,100)) +
  labs(title="Distribution of price by neighbourhood", x = "Neighbourhood",y = "Price (US dollars)")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90))+
  scale_x_discrete(labels = c('I','II','III','IV','IX','V','VI','VII','VIII','X','XI','XII','XIII','XIV','XV'))
price_neighbourhood_boxplot

```


## Modelling

Before starting the modeling I separated my observations to a training set (random 70% of our data) and a holdout set (random 30% of our data). During the modeling I used 5-fold cross validation as control and I based my modeling decisions on the average of the 5 RMSEs calculated from the five folds.

During the modeling exercise I created 6 models:

- **OLS** using basic variables
- **OLS** using basic and review variables
- **LASSO** using the extended model with basic variables, review, amenities and interactions
- **CART** using the extended model with basic and review variables and amenities
- **Random Forest** using basic and review variables
- **Random Forest** using the extended model with basic and review variables and amenities


```{r message=FALSE, warning=FALSE, echo=FALSE}

# Set up variable groups---------------------------------------------------

basic_vars <- c(
  "n_accommodates", "n_beds", "n_days_since",
  "f_property_type","f_room_type", "f_bathroom", "f_cancellation_policy", "f_bed_type",
  "f_neighbourhood_cleansed")

# reviews
reviews <- c("f_number_of_reviews","n_review_scores_rating", "flag_review_scores_rating")

#not use p_host_response_rate and usd_cleaning_fee due to missing values

# Dummy variables
amenities <-  grep("^d_.*", names(data), value = TRUE)

# interactions for the LASSO
X1  <- c("n_accommodates*f_property_type",  "f_room_type*f_property_type",  "f_room_type*d_familykidfriendly",
         "d_airconditioning*f_property_type", "d_cats*f_property_type", "d_dogs*f_property_type",
         "f_room_type*d_balcony","f_room_type*d_pool")
# with boroughs
X2  <- c("f_property_type*f_neighbourhood_cleansed", "f_room_type*f_neighbourhood_cleansed",
         "n_accommodates*f_neighbourhood_cleansed" )


predictors_1 <- c(basic_vars)
predictors_2 <- c(basic_vars, reviews)
predictors_3 <- c(basic_vars, reviews, amenities)
predictors_E <- c(basic_vars, reviews, amenities, X1,X2)

# Separate hold-out set ---------------------------------------------------

set.seed(2021)

train_indices <- as.integer(createDataPartition(data$price, p = 0.7, list = FALSE))
data_train <- data[train_indices, ]
data_holdout <- data[-train_indices, ]


# Modelling ---------------------------------------------------------------


# do 5-fold CV
train_control <- trainControl(method = "cv",
                              number = 5,
                              verboseIter = FALSE)



ols_model <- readRDS( paste0(dir,'/out/OLS1.rds'))
ols_model2 <- readRDS( paste0(dir,'/out/OLS2.rds'))
lasso_model <- readRDS( paste0(dir,'/out/lasso.rds'))
cart_model <- readRDS( paste0(dir,'/out/cart.rds'))
rf_model_1 <- readRDS( paste0(dir,'/out/RF1.rds'))
rf_model_2 <- readRDS( paste0(dir,'/out/RF2.rds'))

# evaluate random forests -------------------------------------------------

results <- resamples(
  list(
    model_1  = rf_model_1,
    model_2  = rf_model_2
  )
)


# Turning parameter choice 1
result_1 <- matrix(c(
  rf_model_1$finalModel$mtry,
  rf_model_2$finalModel$mtry,
  rf_model_1$finalModel$min.node.size,
  rf_model_2$finalModel$min.node.size
),
nrow=2, ncol=2,
dimnames = list(c("Model 1", "Model 2"),
                c("Min vars","Min nodes"))
)
#result_1

# Turning parameter choice 2
result_2 <- matrix(c(mean(results$values$`model_1~RMSE`),
                     mean(results$values$`model_2~RMSE`)
),
nrow=2, ncol=1,
dimnames = list(c("Model 1", "Model 2"),
                c(results$metrics[2]))
)
#result_2


# Compare models ----------------------------------------------------------


final_models <-
  list("OLS" = ols_model,
       "OLS (basic + reviews)" = ols_model2,
       "LASSO (model with interactions)" = lasso_model,
       "CART" = cart_model,
       "Random forest basic + reviews)" = rf_model_1,
       "Random forest (with amenities)" = rf_model_2)

results <- resamples(final_models) %>% summary()
#results


```


The results of the models can be found below. Based on the model results the extended Random Forest model performed the best. Using 5-fold cross-validation it has an 44.9 USD RMSE meaning approximately 50% of the average apartment price (average price is 88.3 USD) and an R-squared of 40%. Based on these information I would choose this model as my final choice, but we should highlight that as the second OLS model, with basic and review variables, performed also relatively good, if the key decision point is interpretation then it can be also a good choice.


```{r echo=FALSE, message=FALSE, warning=FALSE}

# Model selection is carried out on this CV RMSE
# CART and Random forest (smaller model) are performing worse
result_3 <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~Rsquared")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV Rsquared" = ".")
#result_3

knitr::kable(result_3,caption="Models R-squared")

result_4 <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~RMSE")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV RMSE" = ".")
#result_4

knitr::kable(result_4,caption="Models RMSE")

# Based on MAE, RMSE, R-squared the second RF model is our final model with 10 min vars 5 min nodes

```

After running our models on the training sample let's have a look at their performance on the holdout set. Based on the results below we can see that the second random forest 46.1 USD RMSE performs a similar RMSE compared to the training set .


```{r message=FALSE, warning=FALSE, echo=FALSE}


### evaluate preferred model on the holdout set

result_5 <- map(final_models, ~{
  RMSE(predict(.x, newdata = data_holdout), data_holdout[["price"]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("Holdout RMSE" = ".")

knitr::kable(result_5,caption="Holdout models RMSE")

```

# Variable importance

I decided to select the extended random forest model. Below on the variable importance charts the key predictors of the selected random forest model can be seen. Interesting fact is that the top 10 predictor variable accounts approximately 48% of the model prediction power.

```{r message=FALSE, warning=FALSE, echo=FALSE, out.width = '50%', fig.height=6}

# first need a function to calculate grouped varimp
group.importance <- function(rf.obj, groups) {
  var.imp <- as.matrix(sapply(groups, function(g) {
    sum(importance(rf.obj)[g], na.rm = TRUE)
  }))
  colnames(var.imp) <- "MeanDecreaseGini"
  return(var.imp)
}

rf_model_2_var_imp <- importance(rf_model_2$finalModel)/1000
rf_model_2_var_imp_df <-
  data.frame(varname = names(rf_model_2_var_imp),imp = rf_model_2_var_imp) %>%
  mutate(varname = gsub("f_neighbourhood_cleansed", "Borough:", varname) ) %>%
  mutate(varname = gsub("f_room_type", "Room type:", varname) ) %>%
  arrange(desc(imp)) %>%
  mutate(imp_percentage = imp/sum(imp))


# full varimp plot, top 10 only

# have a version with top 10 variables
rf_model_2_var_imp_plot_b <- ggplot(rf_model_2_var_imp_df[1:10,], aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color="indianred3", size=2) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color="indianred3", size=1) +
  ylab("Importance (Percent)") +
  labs(title="Top 10 most important variables")+
  coord_flip() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw() +
  theme(axis.text.x = element_text(size=11), axis.text.y = element_text(size=11),
        axis.title.x = element_text(size=11), axis.title.y = element_text(size=11))
rf_model_2_var_imp_plot_b

# grouped variable importance - keep binaries created off factors together

varnames <- rf_model_2$finalModel$xNames
f_neighbourhood_cleansed_varnames <- grep("f_neighbourhood_cleansed",varnames, value = TRUE)
f_cancellation_policy_varnames <- grep("f_cancellation_policy",varnames, value = TRUE)
f_bed_type_varnames <- grep("f_bed_type",varnames, value = TRUE)
f_property_type_varnames <- grep("f_property_type",varnames, value = TRUE)
f_room_type_varnames <- grep("f_room_type",varnames, value = TRUE)

groups <- list(f_neighbourhood_cleansed=f_neighbourhood_cleansed_varnames,
               f_cancellation_policy = f_cancellation_policy_varnames,
               f_bed_type = f_bed_type_varnames,
               f_property_type = f_property_type_varnames,
               f_room_type = f_room_type_varnames,
               f_bathroom = "f_bathroom",
               n_days_since = "n_days_since",
               n_accommodates = "n_accommodates",
               n_beds = "n_beds")

rf_model_2_var_imp_grouped <- group.importance(rf_model_2$finalModel, groups)
rf_model_2_var_imp_grouped_df <- data.frame(varname = rownames(rf_model_2_var_imp_grouped),
                                            imp = rf_model_2_var_imp_grouped[,1])  %>%
  mutate(imp_percentage = imp/sum(imp))

rf_model_2_var_imp_grouped_plot <-
  ggplot(rf_model_2_var_imp_grouped_df, aes(x=reorder(varname, imp), y=imp_percentage)) +
  geom_point(color="indianred3", size=2) +
  geom_segment(aes(x=varname,xend=varname,y=0,yend=imp_percentage), color="indianred3", size=1) +
  xlab("Variable Name") +
  labs(title="Top grouped variable importance")+
  coord_flip() +
  # expand=c(0,0),
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_bw() +
  theme(axis.text.x = element_text(size=11), axis.text.y = element_text(size=11),
        axis.title.x = element_text(size=11), axis.title.y = element_text(size=11))
rf_model_2_var_imp_grouped_plot


```


## Partial Dependence

Based on the summary table below we can strenghten most of our inspections from the exploratory data analysis that larger apartments (4-6 persons) are way more expensive than small apartments (2-3 persons) and overall condominiums are cheaper. But there are no significant difference between the prediction error of these categories. The neighbourhoods supports our previous statements as well showing that the I, II and XIII are the most expensive. It is interesting that regarding the RMSE price we can see that in the III, IV and VI neighbourhoods our model performed much worse than in the others occuring more than 72-86% of uncertainty in price prediction. Interestingly there does not seem to be any pattern in the neihbourhoods RMSE regarding mean prices, so we can not state that the model tends to predict better lower prices or not.

```{r message=FALSE, warning=FALSE, echo=FALSE}

# Subsample performance: RMSE / mean(y) ---------------------------------------
# NOTE  we do this on the holdout set.

# ---- cheaper or more expensive flats - not used in book
data_holdout_w_prediction <- data_holdout %>%
  mutate(predicted_price = predict(rf_model_2, newdata = data_holdout))



######### create nice summary table of heterogeneity
a <- data_holdout_w_prediction %>%
  mutate(is_low_size = ifelse(n_accommodates <= 3, "small apt", "large apt")) %>%
  group_by(is_low_size) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = RMSE(predicted_price, price) / mean(price)
  )

b <- data_holdout_w_prediction %>%
  filter(f_neighbourhood_cleansed %in% c("I Centro Storico", "II Parioli/Nomentano", "III Monte Sacro", "IV Tiburtina", "V Prenestino/Centocelle", "VI Roma delle Torri", "VII San Giovanni/Cinecitta", "VIII Appia Antica", "IX Eur", "X Ostia/Acilia", "XI Arvalia/Portuense", "XII Monte Verde", "XIII Aurelia", "XIV Monte Mario", "XV Cassia/Flaminia")) %>%
  group_by(f_neighbourhood_cleansed) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = rmse / mean_price
  )

c <- data_holdout_w_prediction %>%
  filter(f_property_type %in% c("Apartment", "Condominium")) %>%
  group_by(f_property_type) %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = rmse / mean_price
  )


d <- data_holdout_w_prediction %>%
  dplyr::summarise(
    rmse = RMSE(predicted_price, price),
    mean_price = mean(price),
    rmse_norm = RMSE(predicted_price, price) / mean(price)
  )

# Save output
colnames(a) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(b) <- c("", "RMSE", "Mean price", "RMSE/price")
colnames(c) <- c("", "RMSE", "Mean price", "RMSE/price")
d<- cbind("All", d)
colnames(d) <- c("", "RMSE", "Mean price", "RMSE/price")

line1 <- c("Type", "", "", "")
line2 <- c("Apartment size", "", "", "")
line3 <- c("Borough", "", "", "")

result_6 <- rbind(line2, a, line1, c, line3, b, d) %>%
  transform(RMSE = as.numeric(RMSE), `Mean price` = as.numeric(`Mean price`),
            `RMSE/price` = as.numeric(`RMSE/price`))
#result_6

knitr::kable(result_6,caption="Subsample performance")

```

## Actual versus predicted price

Finally let's have a look at how the model predicted the actual prices. We can see that prices spread wide around the line, so we can not say that the prediction covers variety in prices. Also based on the chart below we can suspect that the model overpriced the cost of several apartments which probably caused the relatively large RMSE.

```{r message=FALSE, warning=FALSE, echo=FALSE, fig.height=4 }
level_vs_pred <- ggplot(data = data_holdout_w_prediction) +
  geom_point(aes(y=predicted_price, x=price), color = "indianred3", size = 1,
             shape = 16, show.legend=FALSE, na.rm=TRUE) +
  geom_segment(aes(x = 0, y = 0, xend = 500, yend =500), size=0.5, color="black", linetype=2) +
  coord_cartesian(xlim = c(0, 500), ylim = c(0, 500)) +
  scale_x_continuous(expand = c(0.01,0.01),limits=c(0, 500), breaks=seq(0, 500, by=50)) +
  scale_y_continuous(expand = c(0.01,0.01),limits=c(0, 500), breaks=seq(0, 500, by=50)) +
  labs(y = "Price (US dollars)", x = "Predicted price  (US dollars)") +
  theme_bw() 
level_vs_pred
```

## Summary

In this report I tried to find a good model to predict Airbnb prices in Rome. I created six models from which the extended Random Forest performed the best results with 44.9 USD RMSE and 40% R-squared values. Probably one of the key reason of the 40% performance is that the model overpredicts the prices of several Airbnbs. The created model highlights interesting attributes of Airbnbs which could be important for owners to consider as main price drivers, attributes like these includes number of accomodates, number of bathrooms, review scores raing, private room, airconditioning, free parking on street, cancellation policy or number of beds. Finally if someone would like to book a hotel based on the prediction of this model I would suggest to use it only if the person looks for an accomodation in the V Prenestino/Centocelle or XII Monte Verde neighbourhood of Rome as the model provides better prediction there compared to other parts of the city.