---
title: "Finding Best Hotel Deals in Vienna"
author: "Attila Serfozo"
date: '2021-02-14 '
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Set up environment ------------------------------------------------------

rm(list=ls())


# Import libraries
library(tidyverse)
library(scales)
library(xtable)
library(cowplot)
library(glmnet)
library(caret)
library(rattle)

dir <- "D:/Egyetem/CEU/Winter_Term/Data_Analysis_3/Assignments/Assignment_3/"

# load theme and functions
source(paste0(dir,"codes/theme_bg.R"))
source(paste0(dir,"codes/da_helper_functions.R"))

data_in <- paste0(dir,"data/clean/")
data_out <- paste0(dir,"out/")

# load vienna
vienna <- readRDS(paste0(data_in,"hotels-vienna.rds"))

# 3-4 stars, Vienna actual, without  extreme values (price above 600 USD)
vienna <- vienna %>% filter(f_accommodation_type=="Hotel") %>%
  filter(f_city_actual=="Vienna") %>%
  filter(f_stars==3 | f_stars==3.5 | f_stars==4) %>% 
  filter(price<=300)

options(digits = 4)

```

## Abstract

This project aimed to build a hotel price prediction model to find best hotel deals in Vienna on November 2017 and compare the 5 best deals to the results of book Data Analysis for Business, Economics, and Policy by Gabor Bekes and Gabor Kezdi. During the exercise I cleaned the data, grouped variables and created 5 different models. Based on the results the Random forest provided the best prediction with an RMSE of 0.20 USD on log price target variable and an R-squared of 62.4%. But overall we can state that the model tends to underestimate the price of more expensive hotels with prices above 125 USD. In the end I selected the 5 best deals according to my model based on log price differences, and 4 deals out of 5 matched the highlighted hotels from the Gabor Bekes and Gabor Kezdi book.

## Introduction

In this project my goal was to build a price prediction model for 3-4 star hotels in Vienna and compare the best deals to the results of Book Chapter 10 in the Data Analysis for Business, Economics, and Policy by Gabor Bekes and Gabor Kezdi Cambridge University Press 2021. The dataset represents the hotels available on a price comparison site on November 2017. In the exercise to create an accurate prediction I used key variables such as distance from center, number of stars, neighbourhood and review variables such as number of ratings and ratings, tripadvisor ratings. I looked at 5 different models including 3 OLS, a CART and a Random forest and in the end I wanted to finish with a final model with relatively good prediction power regarding it's RMSE and R-squared. Based on the final model I selected the 5 best deals from the dataset and compared them to the highlighted 5 from the Data Analysis for Business, Economics, and Policy book.

## Data Preparation

In the beginning of the data preparation I started with 430 observations and 24 variables, all filtered on November 2017 which got reduced to 428 rows after removing duplicated observations. I also needed to treat missing values, as there were several hotels with missing data on ratings. Therefore I flagged missing values and decided to substitute all with the median of the variables. As a result I finished with 19 cleaned variables including numerical, factored category variables, binaries and flags.

To fit the dataset on the analysis purposes I filtered the clean data to hotels between 3 and 4 stars in Vienna actual. In addition when I had a look at extreme values, I excluded hotels with a one night price above 300 USD as there were one with a price of 383 USD and one with 1012 USD and they significantly lower the prediction accuracy of models. Thus, I finished with 206 observations on 3-4 stars hotels in Vienna. 

Finally I looked at the distributions of key variables and their statistics. As it can be seen on the price distribution below, hotel prices are skewed with a long right tail. To transform it into a closer to normal form I decided to have a look at the logarithmic form and seeing the results I decided to use log price during the modeling exercise as a target variable. Also, based on the similar observation on distance from center I applied a log-form on this variable as well. I also had a look at the distribution of price by stars and tripadvisor rating, the boxplot diagram results can be seen below.

```{r  message=FALSE, warning=FALSE, echo=FALSE, out.width = '50%', fig.height=4}

# Price is skewed with a long right tail
# Logarithmic transformation is preferable
plot_price <- ggplot(data = vienna, aes (x = price)) +
  geom_histogram(binwidth = 10, color = "black", fill = "seagreen4")+
  labs(title="Distribution of price", x = "Price (US dollars)", y = "Frequency") +
  theme_bw() 
plot_price

vienna$lnprice <- log(vienna$price)

# lnprice -> closer to a normal distribution
plot_lnprice <- ggplot(data = vienna, aes (x = lnprice)) +
  geom_histogram(color = "black", fill = "seagreen4")+
  labs(title="Distribution of log price", x = "Price (US dollars)", y = "Frequency") +
  theme_bw() 
plot_lnprice


# Distance is better with a logarithmic transformation
plot_distance <- ggplot(data = vienna, aes (x = n_distance)) +
  geom_histogram(binwidth = 0.3, color = "black", fill = "seagreen4")+
  labs(title="Distribution of distance", x = "Distance to city center (miles)", y = "Frequency") +
  expand_limits(x = 0.01, y = 0.01) +
  # scale_x_continuous(expand = c(0.01,0.01), limits = c(0,14), breaks = seq(0, 14, by = 2)) +
  # scale_y_continuous(expand = c(0.00,0.00), limits = c(0,61), breaks = seq(0, 60, by = 10)) +
  theme_bw() 
plot_distance

vienna$n_distance_log <- log(vienna$n_distance)

plot_lndistance <- ggplot(data = vienna, aes (x = n_distance_log)) +
  geom_histogram(binwidth = 0.3, color = "black", fill = "seagreen4")+
  labs(title="Distribution of log distance", x = "Distance to city center (miles)", y = "Frequency") +
  # expand_limits(x = 0.01, y = 0.01) +
  # scale_x_continuous(expand = c(0.01,0.01), limits = c(0,14), breaks = seq(0, 14, by = 2)) +
  # scale_y_continuous(expand = c(0.00,0.00), limits = c(0,61), breaks = seq(0, 60, by = 10)) +
  theme_bw() 
plot_lndistance


# How does average price changes across variables
# number of stars
boxplot_stars <- ggplot(data = vienna, aes(x = f_stars, y = price)) +
  stat_boxplot(aes(group = f_stars), geom = "errorbar", width = 0.3,
               color = "black", size = 0.5, na.rm=T)+
  geom_boxplot(aes(group = f_stars),
               color = "black", fill = c("seagreen2","seagreen3","seagreen4"),
               size = 0.5, width = 0.6, na.rm=T, outlier.shape = NA) +
  scale_y_continuous(expand = c(0.01,0.01),limits = c(0,300), breaks = seq(0,300,100)) +
  labs(title="Distribution of price by stars",x = "Number of stars",y = "Price (US dollars)")+
  theme_bw()
boxplot_stars

# tripadvisor rating
boxplot_ratingta <- ggplot(data = vienna, aes(x = f_ratingta, y = price)) +
  stat_boxplot(aes(group = f_ratingta), geom = "errorbar", width = 0.3,
               color = "black", size = 0.5, na.rm=T)+
  geom_boxplot(aes(group = f_ratingta),
               color = "black", fill = c("seagreen2", "seagreen2", "seagreen3","seagreen3","seagreen4"),
               size = 0.5, width = 0.6, na.rm=T, outlier.shape = NA) +
  scale_y_continuous(expand = c(0.01,0.01),limits = c(0,300), breaks = seq(0,300,100)) +
  labs(title="Distribution of price by Tripadvisor rating",x = "Rating",y = "Price (US dollars)")+
  theme_bw()
boxplot_ratingta


```

As a last step of the preparations I separated my variables to 3 groups:

- **Main variables:** including distance in log, number of stars, ratings and neighbourhood.
- **Review variables:** including rating count, tripadvisor rating and tripadvisor rating count. I did not include flags as they did not improve the results significantly.
- **Other variables:** including alternative distance, offer available dummy, type of offer and flag if room was noted as scarce.

## Modelling

In this time I did not use 5-fold cross validation for modeling purposes as we just would like to build a model to find the 5 best deals in this data and we are not planning to use this model for external prediction.

I created 5 different models:

- **OLS** using main variables
- **OLS** using main and review variables
- **OLS** using all the variables including main, review and other.
- **CART** using all the variables including main, review and other.
- **Random Forest** using all the variables including main, review and other.

The results of the models can be found below. Based on the model results the Random Forest model performed significantly the best, it had 0.20 USD RMSE on log price and an approximately 62.4% R-squared. Based on the results which can be seen below in the 2 tables my final model choice is the Random forest.

```{r  message=FALSE, warning=FALSE, echo=FALSE}


# Define models -----------------------------------------------------------

main_variables <- c("n_distance_log", "f_stars", "n_rating", "f_neighbourhood")
  
reviews_var <- c("n_rating_count", "f_ratingta", "n_ratingta_count")

other_var <- c("n_distance_alter","d_offer", "d_scarce_room", "f_offer_cat")

X1 <- c(main_variables)
X2 <- c(main_variables, reviews_var)
X3 <- c(main_variables, reviews_var, other_var)


# Modelling ---------------------------------------------------------------


# do 5-fold CV
train_control <- trainControl(method = "cv",
                              number = 5,
                              verboseIter = FALSE)


### OLS

# For main vars
set.seed(2021)
ols_model <- train(
  formula(paste0("lnprice ~", paste0(X1, collapse = " + "))),
  data = vienna,
  method = "lm",
  trControl = train_control
)

ols_model_coeffs <-  ols_model$finalModel$coefficients
ols_model_coeffs_df <- data.frame(
  "variable" = names(ols_model_coeffs),
  "ols_coefficient" = ols_model_coeffs
) %>%
  mutate(variable = gsub("`","",variable))


# For main vars and review vars
set.seed(2021)
ols_model2 <- train(
  formula(paste0("lnprice ~", paste0(X2, collapse = " + "))),
  data = vienna,
  method = "lm",
  trControl = train_control
)

ols_model_coeffs2 <-  ols_model2$finalModel$coefficients
ols_model_coeffs_df2 <- data.frame(
  "variable" = names(ols_model_coeffs2),
  "ols_coefficient" = ols_model_coeffs2
) %>%
  mutate(variable = gsub("`","",variable))

# For main vars and review vars and other vars
set.seed(2021)
ols_model3 <- train(
  formula(paste0("lnprice ~", paste0(X3, collapse = " + "))),
  data = vienna,
  method = "lm",
  trControl = train_control
)

ols_model_coeffs3 <-  ols_model3$finalModel$coefficients
ols_model_coeffs_df3 <- data.frame(
  "variable" = names(ols_model_coeffs3),
  "ols_coefficient" = ols_model_coeffs3
) %>%
  mutate(variable = gsub("`","",variable))


### CART

set.seed(2021)
cart_model <- train(
  formula(paste0("lnprice ~", paste0(X3, collapse = " + "))),
  data = vienna,
  method = "rpart",
  tuneLength = 10,
  trControl = train_control
  
)

#fancyRpartPlot(cart_model$finalModel, sub = "")



### RANDOM FOREST

# set tuning
tune_grid <- expand.grid(
  .mtry = c(9),
  .splitrule = "variance",
  .min.node.size = c(10)
)


# simpler model with basic vars and review vars for model A (1)
set.seed(2021)
rf_model <- train(
  formula(paste0("lnprice ~", paste0(X3, collapse = " + "))),
  data = vienna,
  method = "ranger",
  trControl = train_control,
  tuneGrid = tune_grid,
  importance = "impurity"
)


# Compare models ----------------------------------------------------------

final_models <-
  list("OLS (main)" = ols_model,
       "OLS (main + reviews)" = ols_model2,
       "OLS (main + reviews + others)" = ols_model3,
       "CART" = cart_model,
       "Random forest" = rf_model)

results <- resamples(final_models) %>% summary()

# Model selection is carried out on this CV RMSE
# CART and Random forest (smaller model) are performing worse
result_1 <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~Rsquared")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV Rsquared" = ".")
knitr::kable(result_1,caption="Models R-squared")

result_2 <- imap(final_models, ~{
  mean(results$values[[paste0(.y,"~RMSE")]])
}) %>% unlist() %>% as.data.frame() %>%
  rename("CV RMSE" = ".")
knitr::kable(result_2,caption="Models RMSE")

```

## Actual versus predicted price and Best Deals

As the aim of the project was to predict hotel prices and find the best deals, I had a look at the distribution of predicted prices versus actual prices of hotels, which can be seen below on the scatterplot chart. As we can see the final model tends to underestimate prices of more expensive hotels with prices above 125 USD. On the right scatterplot the 5 best deals can be seen highlighted in red according to the Random forest model.

```{r  message=FALSE, warning=FALSE, echo=FALSE, out.width = '50%', fig.height=4}

# Actual versus predicted -------------------------------------------------

vienna <- vienna %>%
  mutate(predicted_price_ln = predict(rf_model, newdata = vienna))

vienna <- vienna %>%
  mutate(ln_res = lnprice - predicted_price_ln)

std <- sd(vienna$ln_res)

vienna <- vienna %>%
  mutate(predicted_price = round(exp(vienna$predicted_price_ln) * exp((std^2)/2),2))

# Actual versus predicted price

level_vs_pred <- ggplot(data = vienna) +
  geom_point(aes(y=price, x=predicted_price), color = "seagreen4", size = 1.5,
             shape = 16, show.legend=FALSE, na.rm=TRUE) +
  geom_segment(aes(x = 0, y = 0, xend = 250, yend =250), size=0.5, color="black", linetype=2) +
  coord_cartesian(xlim = c(0, 250), ylim = c(0, 250)) +
  scale_x_continuous(expand = c(0.01,0.01),limits=c(0, 250), breaks=seq(0, 250, by=50)) +
  scale_y_continuous(expand = c(0.01,0.01),limits=c(0, 250), breaks=seq(0, 250, by=50)) +
  labs(title="Actual versus predicted hotel prices", y = "Price (US dollars)", x = "Predicted price  (US dollars)") +
  theme_bw() 
level_vs_pred


vienna$bestdeals <- ifelse(vienna$ln_res %in% head(sort(vienna$ln_res),5),TRUE,FALSE)

bestdeals <- ggplot(data = vienna, aes(x = predicted_price, y = price)) +
  geom_point(aes(color=bestdeals,shape=bestdeals), size = 1.5, fill="black", alpha = 0.8, show.legend=F, na.rm = TRUE) + 
  geom_segment(aes(x = 0, y = 0, xend = 250, yend =250), size=0.8, color="seagreen4", linetype=2) +
  labs(title="Best Deals", x = "Predicted price in US dollars ",y = "Price in US dollars")+
  coord_cartesian(xlim = c(0, 250), ylim = c(0, 250)) +
  scale_colour_manual(name='',values=c("grey",'red')) +
  scale_shape_manual(name='',values=c(16,21)) +
  geom_segment(aes(x = 110, y = 55, xend = 140, yend = 110), arrow = arrow(length = unit(0.1, "cm")))+
  geom_segment(aes(x = 100, y = 55, xend = 95, yend = 70), arrow = arrow(length = unit(0.1, "cm")))+
  geom_segment(aes(x = 90, y = 50, xend = 70, yend = 50), arrow = arrow(length = unit(0.1, "cm")))+
  annotate("text", x = 110, y = 50, label = "Best deals", size=2.5)+
  theme_bw() +
  theme(axis.text.x=element_text(size=11)) +
  theme(axis.text.y=element_text(size=11)) +
  theme(axis.title.x=element_text(size=11)) +
  theme(axis.title.y=element_text(size=11)) 
bestdeals

```

Finally the 5 best deals according to the model and the 5 best deals from the book can be found below in the tables. In the selection of the 5 best deals the main decision point was the log price residuals as it can take into account the percentage difference in prices instead of the absolute differences. Out of the 5 best deals highlighted in the book I had only one, hotel ID - 22080, which did not appear to be a best deal according to my final model.

```{r  message=FALSE, warning=FALSE, echo=FALSE}
# Best 5 hotels
vienna <- vienna %>%
  mutate(price_res = round(price - predicted_price,4))

Best_hotels <- vienna %>% select(hotel_id, price, predicted_price, price_res, ln_res, n_distance, f_neighbourhood, f_stars, n_rating) %>%
  arrange(ln_res)

Best5_hotels <- head(Best_hotels,5)

# Best Deals
# IDs: 21912, 22344, 21975, 22184, 22118
colnames (Best5_hotels) <- c("ID","Price USD","Predicted price","Residual", "Log Residual", "Distance","Neighbourhood", "Stars", "Rating")
knitr::kable(Best5_hotels,caption="Best 5 hotels according to the model")

# Best Deals in Book:
# IDs: 21912, 22344, 21975, 22184, 22080
Best5_hotels_book <- Best_hotels[Best_hotels$hotel_id %in% c(21912, 21975, 22344, 22080, 22184),]
colnames (Best5_hotels_book) <- c("ID","Price USD","Predicted price","Residual", "Log Residual", "Distance","Neighbourhood", "Stars", "Rating")
knitr::kable(Best5_hotels_book,caption="Best 5 hotels in the book", row.names = FALSE)

```

## Summary

In this report I tried to find good deals among 3-4 star hotels in Vienna on November 2017. I created 5 models to predict prices from which I selected the Random forest as the final model seeing its predicting power with 0.20 USD RMSE on log price and an approximately 62.4% R-squared value. Overall we can see on the prediction that the model tends to underestimate prices of more expensive hotels with values above 125 USD. In the end I found the 5 best deals in Vienna according to our model based on percentage differences in prices. In the 5 best deals 4 out of 5 matched the ones in the Gabor Bekes and Gabor Kezdi book.
